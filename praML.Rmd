---
title: "Practical Machine Learning on Activity Prediction"
author: "Zhao Hao"
date: "Friday, November 21, 2014"
output: html_document
self_contained: no
---
The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.

#```{r setup, include=FALSE}
opts_chunk$set(dev = 'pdf',cache=TRUE,eval=TRUE)
#```

## Background
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

The goal of this submission is to predict the manner in which they did the exercise which is defined as the "classe" variable in the training set.

## Survey Data
We first select 10 rows of data to see how many variables there are, and check the data structure, names of the variables and the definition of "classe".

```{r,results='hide'}
surveyTrain <- read.csv("data/pml-training.csv", nrows =10)
surveyTest <- read.csv("data/pml-testing.csv", nrows=10)
str(surveyTrain);
names(surveyTrain)
surveyTrain$classe
```

Some variables have many NAs. We will clean those variables up.

```{r,results='hide'}
surveyTrain <- surveyTrain[,complete.cases(t(surveyTrain))]
surveyTrain
```

And we also determines that the first 6 variables are not relevant to the data set, so we also will clean them up.

```{r,results='hide'}
irVar <- c(1:6)
surveyTrain[,-irVar]
```

## Build, Partition and Tidy Up Data Sets
Now we have a good idea about the data. We now read in all the data and tidy them up.

```{r}
rm(surveyTrain, surveyTest)

testing <- read.csv("data/pml-testing.csv", na.strings=c("", "NA", "NULL"))
testing <- testing[, complete.cases(t(testing))]
testing <- testing[,-irVar]
rawdata<-read.csv("data/pml-training.csv", na.strings=c("", "NA", "NULL"))
rawdata <- rawdata[, complete.cases(t(rawdata))]
rawdata <- rawdata[,-irVar]
```

And we partition the data into testing, validating and training sets. 

```{r}
set.seed(112014)
library(lattice)
library(ggplot2)
library(caret)
inTrain <- createDataPartition(rawdata$classe, p=0.7, list=F)
training <- rawdata[inTrain,]
valid <- rawdata[-inTrain,]
```

## Train with Different Models
Now we choose three different models to train on the training data. Meanwhile we record the running time of each model for future comparison.

```{r, cache=TRUE}
library(randomForest)
library(plyr)
library(splines)
library(survival)
library(parallel)
library(gbm)
set.seed(235)
ptm.start <- proc.time()
rfMod<-randomForest(classe~., data=training)
ptm.rf <- proc.time() - ptm.start
ptm.start <- proc.time()
gbmMod<-train(classe~., data=training, method="gbm", verbose=F)
ptm.gbm <- proc.time() - ptm.start
ptm.start <- proc.time()
ldaMod<-train(classe~., data=training, method="lda")
ptm.lda <- proc.time() - ptm.start
```

Now we can check which model runs the fastest. Here is the result:

```{r, echo=FALSE}
ptm<-list(rf=ptm.rf, gbm=ptm.gbm, lda=ptm.lda)
ptm
```

The linear model finishes the first, not much a surprise. It took quite a while for GBM (Generalized Boosted Regression Modeling) to finish its work. Would it give us the best result?

Now let's figure that out by calculating the accuracy of the predictions on the cross-validation data,

```{r}
rfpred<-predict(rfMod, valid)
gbmpred<-predict(gbmMod, valid)
ldapred<-predict(ldaMod, valid)
```

with this accuracy function.

```{r}
accuracy<-function(pre,val){
  sum(pre==val)/length(val)
}
```
Here is the result:
```{r, echo=FALSE}
accu <- list(rf=accuracy(rfpred,valid$classe),
     gbm = accuracy(gbmpred,valid$classe),
     lda = accuracy(ldapred,valid$classe))
accu
```
So the winner is actually the random forest, which beats the GBM by 0.01% !!

## Prediction on Test Data
Finally we will use the randomforest model to predict the personal activity. The last cross-validation result is very impressive so we don't have to do a k-fold cross-validation to further evaluate the models. The test data will further prove that this prediction model is quite robust.

We save the result and submit the result for the final evaluation.

```{r, eval=FALSE}
answers<-predict(rfMod, testing)
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("answers/problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(answers)
```
